[2025-07-13 23:23:31,692] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-13 23:23:36,145] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2025-07-13 23:23:36,172] [INFO] [runner.py:568:main] cmd = /home/amaurya/softwares/miniconda3/envs/dspd_env/bin/python3.12 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/..//Megatron-DeepSpeed/pretrain_gpt.py --tensor-model-parallel-size 1 --num-layers 128 --hidden-size 5120 --num-attention-heads 40 --micro-batch-size 1 --global-batch-size 4 --ffn-hidden-size 20480 --seq-length 2048 --max-position-embeddings 2048 --train-iters 10 --data-path /home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/my-gpt2_text_document --vocab-file /home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/gpt2-vocab.json --merge-file /home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/gpt2-merges.txt --data-impl mmap --tokenizer-type GPT2BPETokenizer --split 949,50,1 --distributed-backend nccl --lr 3e-4 --lr-decay-style cosine --min-lr 3e-5 --weight-decay 0.1 --clip-grad 1 --lr-warmup-iters 1 --optimizer adam --adam-beta1 0.9 --adam-beta2 0.95 --log-interval 1 --save-interval 1000 --eval-interval 1000 --eval-iters 0 --bf16 --no-query-key-layer-scaling --attention-dropout 0 --hidden-dropout 0 --use-rotary-position-embeddings --untie-embeddings-and-output-weights --swiglu --normalization rmsnorm --disable-bias-linear --num-key-value-heads 4 --deepspeed --exit-interval 200 --deepspeed_config=/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/logs//ds_config.json --zero-stage=3 --no-pipeline-parallel --cpu-optimizer --checkpoint-activations --deepspeed-activation-checkpointing
[2025-07-13 23:23:38,317] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-13 23:23:40,675] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2025-07-13 23:23:40,675] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0
[2025-07-13 23:23:40,675] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2025-07-13 23:23:40,675] [INFO] [launch.py:163:main] dist_world_size=4
[2025-07-13 23:23:40,675] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2025-07-13 23:23:40,676] [INFO] [launch.py:253:main] process 43047 spawned with command: ['/home/amaurya/softwares/miniconda3/envs/dspd_env/bin/python3.12', '-u', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/..//Megatron-DeepSpeed/pretrain_gpt.py', '--local_rank=0', '--tensor-model-parallel-size', '1', '--num-layers', '128', '--hidden-size', '5120', '--num-attention-heads', '40', '--micro-batch-size', '1', '--global-batch-size', '4', '--ffn-hidden-size', '20480', '--seq-length', '2048', '--max-position-embeddings', '2048', '--train-iters', '10', '--data-path', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/my-gpt2_text_document', '--vocab-file', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/gpt2-vocab.json', '--merge-file', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/gpt2-merges.txt', '--data-impl', 'mmap', '--tokenizer-type', 'GPT2BPETokenizer', '--split', '949,50,1', '--distributed-backend', 'nccl', '--lr', '3e-4', '--lr-decay-style', 'cosine', '--min-lr', '3e-5', '--weight-decay', '0.1', '--clip-grad', '1', '--lr-warmup-iters', '1', '--optimizer', 'adam', '--adam-beta1', '0.9', '--adam-beta2', '0.95', '--log-interval', '1', '--save-interval', '1000', '--eval-interval', '1000', '--eval-iters', '0', '--bf16', '--no-query-key-layer-scaling', '--attention-dropout', '0', '--hidden-dropout', '0', '--use-rotary-position-embeddings', '--untie-embeddings-and-output-weights', '--swiglu', '--normalization', 'rmsnorm', '--disable-bias-linear', '--num-key-value-heads', '4', '--deepspeed', '--exit-interval', '200', '--deepspeed_config=/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/logs//ds_config.json', '--zero-stage=3', '--no-pipeline-parallel', '--cpu-optimizer', '--checkpoint-activations', '--deepspeed-activation-checkpointing']
[2025-07-13 23:23:40,677] [INFO] [launch.py:253:main] process 43048 spawned with command: ['/home/amaurya/softwares/miniconda3/envs/dspd_env/bin/python3.12', '-u', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/..//Megatron-DeepSpeed/pretrain_gpt.py', '--local_rank=1', '--tensor-model-parallel-size', '1', '--num-layers', '128', '--hidden-size', '5120', '--num-attention-heads', '40', '--micro-batch-size', '1', '--global-batch-size', '4', '--ffn-hidden-size', '20480', '--seq-length', '2048', '--max-position-embeddings', '2048', '--train-iters', '10', '--data-path', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/my-gpt2_text_document', '--vocab-file', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/gpt2-vocab.json', '--merge-file', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/gpt2-merges.txt', '--data-impl', 'mmap', '--tokenizer-type', 'GPT2BPETokenizer', '--split', '949,50,1', '--distributed-backend', 'nccl', '--lr', '3e-4', '--lr-decay-style', 'cosine', '--min-lr', '3e-5', '--weight-decay', '0.1', '--clip-grad', '1', '--lr-warmup-iters', '1', '--optimizer', 'adam', '--adam-beta1', '0.9', '--adam-beta2', '0.95', '--log-interval', '1', '--save-interval', '1000', '--eval-interval', '1000', '--eval-iters', '0', '--bf16', '--no-query-key-layer-scaling', '--attention-dropout', '0', '--hidden-dropout', '0', '--use-rotary-position-embeddings', '--untie-embeddings-and-output-weights', '--swiglu', '--normalization', 'rmsnorm', '--disable-bias-linear', '--num-key-value-heads', '4', '--deepspeed', '--exit-interval', '200', '--deepspeed_config=/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/logs//ds_config.json', '--zero-stage=3', '--no-pipeline-parallel', '--cpu-optimizer', '--checkpoint-activations', '--deepspeed-activation-checkpointing']
[2025-07-13 23:23:40,678] [INFO] [launch.py:253:main] process 43049 spawned with command: ['/home/amaurya/softwares/miniconda3/envs/dspd_env/bin/python3.12', '-u', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/..//Megatron-DeepSpeed/pretrain_gpt.py', '--local_rank=2', '--tensor-model-parallel-size', '1', '--num-layers', '128', '--hidden-size', '5120', '--num-attention-heads', '40', '--micro-batch-size', '1', '--global-batch-size', '4', '--ffn-hidden-size', '20480', '--seq-length', '2048', '--max-position-embeddings', '2048', '--train-iters', '10', '--data-path', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/my-gpt2_text_document', '--vocab-file', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/gpt2-vocab.json', '--merge-file', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/gpt2-merges.txt', '--data-impl', 'mmap', '--tokenizer-type', 'GPT2BPETokenizer', '--split', '949,50,1', '--distributed-backend', 'nccl', '--lr', '3e-4', '--lr-decay-style', 'cosine', '--min-lr', '3e-5', '--weight-decay', '0.1', '--clip-grad', '1', '--lr-warmup-iters', '1', '--optimizer', 'adam', '--adam-beta1', '0.9', '--adam-beta2', '0.95', '--log-interval', '1', '--save-interval', '1000', '--eval-interval', '1000', '--eval-iters', '0', '--bf16', '--no-query-key-layer-scaling', '--attention-dropout', '0', '--hidden-dropout', '0', '--use-rotary-position-embeddings', '--untie-embeddings-and-output-weights', '--swiglu', '--normalization', 'rmsnorm', '--disable-bias-linear', '--num-key-value-heads', '4', '--deepspeed', '--exit-interval', '200', '--deepspeed_config=/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/logs//ds_config.json', '--zero-stage=3', '--no-pipeline-parallel', '--cpu-optimizer', '--checkpoint-activations', '--deepspeed-activation-checkpointing']
[2025-07-13 23:23:40,679] [INFO] [launch.py:253:main] process 43050 spawned with command: ['/home/amaurya/softwares/miniconda3/envs/dspd_env/bin/python3.12', '-u', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/..//Megatron-DeepSpeed/pretrain_gpt.py', '--local_rank=3', '--tensor-model-parallel-size', '1', '--num-layers', '128', '--hidden-size', '5120', '--num-attention-heads', '40', '--micro-batch-size', '1', '--global-batch-size', '4', '--ffn-hidden-size', '20480', '--seq-length', '2048', '--max-position-embeddings', '2048', '--train-iters', '10', '--data-path', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/my-gpt2_text_document', '--vocab-file', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/gpt2-vocab.json', '--merge-file', '/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/dataset/gpt2-merges.txt', '--data-impl', 'mmap', '--tokenizer-type', 'GPT2BPETokenizer', '--split', '949,50,1', '--distributed-backend', 'nccl', '--lr', '3e-4', '--lr-decay-style', 'cosine', '--min-lr', '3e-5', '--weight-decay', '0.1', '--clip-grad', '1', '--lr-warmup-iters', '1', '--optimizer', 'adam', '--adam-beta1', '0.9', '--adam-beta2', '0.95', '--log-interval', '1', '--save-interval', '1000', '--eval-interval', '1000', '--eval-iters', '0', '--bf16', '--no-query-key-layer-scaling', '--attention-dropout', '0', '--hidden-dropout', '0', '--use-rotary-position-embeddings', '--untie-embeddings-and-output-weights', '--swiglu', '--normalization', 'rmsnorm', '--disable-bias-linear', '--num-key-value-heads', '4', '--deepspeed', '--exit-interval', '200', '--deepspeed_config=/home/amaurya/dl-io/datastates-artifacts/mlp-offload/scripts/logs//ds_config.json', '--zero-stage=3', '--no-pipeline-parallel', '--cpu-optimizer', '--checkpoint-activations', '--deepspeed-activation-checkpointing']
[2025-07-13 23:23:44,451] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-13 23:23:44,890] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-13 23:23:44,919] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-13 23:23:44,977] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [92m[OKAY][0m
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
async_io ............... [92m[YES][0m ...... [92m[OKAY][0m
fused_adam ............. [92m[YES][0m ...... [92m[OKAY][0m
cpu_adam ............... [92m[YES][0m ...... [92m[OKAY][0m
cpu_adagrad ............ [92m[YES][0m ...... [92m[OKAY][0m
cpu_lion ............... [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... [93m[NO][0m ....... [93m[NO][0m
fused_lamb ............. [92m[YES][0m ...... [92m[OKAY][0m
fused_lion ............. [93m[NO][0m ....... [92m[OKAY][0m
inference_core_ops ..... [93m[NO][0m ....... [92m[OKAY][0m
cutlass_ops ............ [93m[NO][0m ....... [92m[OKAY][0m
transformer_inference .. [93m[NO][0m ....... [92m[OKAY][0m
quantizer .............. [93m[NO][0m ....... [92m[OKAY][0m
ragged_device_ops ...... [93m[NO][0m ....... [92m[OKAY][0m
ragged_ops ............. [93m[NO][0m ....... [92m[OKAY][0m
random_ltd ............. [93m[NO][0m ....... [92m[OKAY][0m
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.5
[93m [WARNING] [0m using untested triton version (3.1.0), only 1.0.0 is known to be compatible
sparse_attn ............ [93m[NO][0m ....... [93m[NO][0m
spatial_inference ...... [93m[NO][0m ....... [92m[OKAY][0m
transformer ............ [92m[YES][0m ...... [92m[OKAY][0m
stochastic_transformer . [93m[NO][0m ....... [92m[OKAY][0m
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/home/amaurya/softwares/miniconda3/envs/dspd_env/lib/python3.12/site-packages/torch']
torch version .................... 2.5.1+cu121
deepspeed install path ........... ['/home/amaurya/softwares/miniconda3/envs/dspd_env/lib/python3.12/site-packages/deepspeed']
deepspeed info ................... 0.13.3+f25903ec6, f25903ec6, dist_nvme_opt
torch cuda version ............... 12.1
torch hip version ................ None
nvcc version ..................... 12.3
deepspeed wheel compiled w. ...... torch 2.5, cuda 12.1
shared memory (/dev/shm) size .... 251.38 GB
**** Git info for Megatron: git_hash=7bba400 git_branch=main ****
